Residualsorted<-sort(Noises)
deltaResidual<-diff(Residualsorted)
lambda<-lambda0*2*N*sd(Noises)^3 #sd(X)^3: to make lambda scale invariant
A <- diag(N)
diag(A[-1,]) <- -1
B <- diag(N)
diag(B[-1,]) <- 1
W <- diag(c(0,1/deltaResidual))
v<-N:1
AAt_inv<-pmin(matrix(v, nrow=N, ncol=length(v), byrow=TRUE),matrix(v, nrow=N, ncol=length(v), byrow=FALSE))#solve(A%*%t(A))
A_Binv<-matrix(2,ncol=N,nrow=N)
A_Binv[upper.tri(A_Binv, diag = TRUE)]<-0
A_Binv<-A_Binv+diag(N)
A_Binv<-A_Binv*sign(toeplitz(1:N%%2)-0.5)#A%*%solve(B)
TEMP<-diag(c(1,deltaResidual^2))%*%AAt_inv+12*lambda*W
Schur<-TEMP[-1,-1]
Schur<-solve(Schur-matrix(TEMP[-1,1])%*%t(matrix(TEMP[1,-1]))/TEMP[1,1])
TEMP<--t(matrix(TEMP[1,-1]))%*%Schur/TEMP[1,1]
TEMP<-6*lambda*rbind(TEMP,Schur)
TEMP<-cbind(rep(0,N),TEMP)
gstarprime <- solve(lambda*(t(A_Binv)%*%W%*%A_Binv+3*W)-6*lambda*W^2%*%TEMP,(N:1)%%2)
# gstar=(g*(T1),...,g*(Tn)) is the negative score
# gstarprime=(g*'(T1),...,g*'(Tn))
gstarprime <- solve(lambda*(t(A_Binv)%*%W%*%A_Binv+3*W)-6*lambda*W^2%*%TEMP,(N:1)%%2)
gstar <- TEMP%*%gstarprime
gstarprime <- cumsum(gstarprime*sign((1:N)%%2-0.5))*sign((1:N)%%2-0.5)#solve(B)%*%gstarprime
gstar <- cumsum(gstar)#solve(A)%*%gstar
#sum(gstar) #check == 0
#############plot g*############
gstars<-function(x,knots,gstar,gstarprime){
N<-length(knots)
deltaknots<-diff(knots)
secantslopes<-diff(gstar)/deltaknots
sumgprime<-gstarprime[-N]+gstarprime[-1]
sumgprime1<-2*gstarprime[-N]+gstarprime[-1]
gvalues<-rep(0, length(x))
index<-findInterval(x, knots)
gvalues[index==0]<-gstar[1]+gstarprime[1]*(x[index==0]-knots[1])
gvalues[index==N]<-gstar[N]+gstarprime[N]*(x[index==N]-knots[N])
cubicpts<-!index%in%c(0,N)
cubicindex<-index[cubicpts]
y<-(x[cubicpts]-knots[cubicindex])/deltaknots[cubicindex]
temp<-gstarprime[cubicindex]*y+(3*secantslopes[cubicindex]-sumgprime1[cubicindex])*y^2+(sumgprime[cubicindex]-2*secantslopes[cubicindex])*y^3
temp<-temp*deltaknots[cubicindex]+gstar[cubicindex]
gvalues[cubicpts]<-temp
return(gvalues)
}
#set grid
xgrid=(-1100:1100)/1000
tailgrid<-(1:max((N/100),7))*mean(deltaResidual)
tailY<-gstar[N]+tailgrid*gstarprime[N]
Negtailgrid<-(-max((N/100),7):-1)*mean(deltaResidual)
NegtailY<-gstar[1]+Negtailgrid*gstarprime[1]
Xplot<-c(Negtailgrid+Residualsorted[1],Residualsorted,tailgrid+Residualsorted[N],xgrid)
Yplot<-c(NegtailY,gstar,tailY,gstars(xgrid,Residualsorted,gstar,gstarprime))
mydf = data.frame(X = Xplot, Y = Yplot)
plot0.obj <- ggplot(data=mydf)+geom_line(aes(x=X, y=Y), color="blue")+geom_line(aes(x=X, y=(sign(X)+1)*X/2), color="red")
grid.arrange(plot0.obj)
#library(RSpectra) #svds() used in gradient descent
library(ggplot2)
library(gridExtra)
library(pracma)
#library(gnorm) #to generate generalized Gaussian
#rm(list = ls())  # clear all variables in workspace
#graphics.off()  # clear all plots
##set the penalization coefficient
lambda0 <- 1e-4
##sample size
N<-2000
noise<-"gaussian"
noise<-"laplace"
noise<-"cauchy"
##generate data
if (noise=="gaussian"){
X<-rnorm(N,0,1)
}else if (noise=="cauchy"){
X<-rcauchy(N)
}else if (noise=="laplace"){
X<-rexp(N)
X<-X*sign(runif(N,-1,1))
}
##return (g'(0),g'(T1),...,g'(Tn)), where g = -psi is increasing
symmetric_neg_decr_score_est <- function(X, thetapilot=0, lambda_0=1e-4){
N<-length(X)
lambda<-lambda0*2*N*sd(X)^3 #sd(X)^3: to make lambda scale invariant
Xsorted<-sort(abs(X-thetapilot))
deltaX<-diff(c(0,Xsorted))
##small scale projected Newton
u<-c(0,rep(1,N)) # linear part of the objective function
D1<-t(matrix(replicate(N,deltaX),ncol=N))
D1[upper.tri(D1)] <- 0
A<-diag(x=1, nrow = N, ncol = N+1)
diag(A[,-1])<-1
D2<-diag(1/deltaX*lambda) #lambda= lambda0*2*N*sd(X)^3
B<-diag(x=1, nrow = N, ncol = N+1)
diag(B[,-1])<--1
Hess<-0.25*crossprod(D1%*%A)+t(B)%*%D2%*%B
# Here, Hess=0.5*Hessian of the objective function, (Hess%*%C-u)=0.5*gradient
##initialization, C=(g'(0),g'(T1),...,g'(Tn))
# objective function: t(C)%*%Hess%*%C - 2*t(u)%*%C
# g = -psi is monotone increasing
C<-solve(Hess,u)
C[C<0]<-0 #projection
###projected Newton
M<-20
for (i in 1:M) {
cat("Newton loop loss",t(C)%*%Hess%*%C-2*t(u)%*%C,"\n")
alpha<-1 #reset step size
# Fixed<-(C==0)*(Hess%*%C-u>0)
# Free<-!Fixed
Free<-(C>0)|(Hess%*%C-u<=0)
###no backtracking for alpha
# C[Free]<-C[Free]-alpha*Scaling[Free,Free]%*%(Hess%*%C-u)[Free]
# C[Free][C[Free]<0]<-0#projection
###backtracking
Ctemp<-C
gradient<-(Hess%*%C-u)[Free]
Update<-solve(Hess[Free,Free],gradient)
Ctemp[Free]<-C[Free]-alpha*Update
Ctemp[Free][Ctemp[Free]<0]<-0 #projection
while (t(Ctemp)%*%Hess%*%Ctemp-2*t(u)%*%Ctemp > t(C)%*%Hess%*%C-2*t(u)%*%C+0.5*t((Ctemp-C)[Free])%*%(2*gradient)) {
alpha<-alpha*0.8
print("shrink step size")
Ctemp[Free]<-C[Free]-alpha*Update
Ctemp[Free][Ctemp[Free]<0]<-0 #projection
}
if(sum((Ctemp-C)^2)<1e-30){
cat("the last update has Euclidean norm",sum((Ctemp-C)^2))
cat("the last step size",alpha)
C<-Ctemp
break
}
C<-Ctemp
}
return(C)
}
# Obtain (g*(0),g*(T1),...,g*(Tn)) from C=(g'(0),g'(T1),...,g'(Tn))
neg_dec_score<-function(X, C, thetapilot=0){
N<-length(X)
Xsorted<-sort(abs(X-thetapilot))
deltaX<-diff(c(0,Xsorted))
gvalues<-C[-1]+C[-(N+1)]
gvalues<-0.5*gvalues*deltaX
for (j in 2:N) {
gvalues[j]<-gvalues[j]+gvalues[j-1]
}
gvalues<-c(0,gvalues) #gvalues = (g*(0),g*(T1),...,g*(Tn))
return(gvalues)
}
######## G' = g*, neg_loglikelihd = (G(0):=0,G(T1),...,G(Tn)), no normalization########
neg_loglikelihd<-function(X, C, gvalues, thetapilot=0){
N<-length(X)
Xsorted<-sort(abs(X-thetapilot))
deltaX<-diff(c(0,Xsorted))
Negloglikelihd<-gvalues[-(N+1)]*deltaX+(C[-(N+1)]/2+(C[-1]-C[-(N+1)])/6)*deltaX^2
for (j in 2:N) {
Negloglikelihd[j]<-Negloglikelihd[j]+Negloglikelihd[j-1]
}
Negloglikelihd<-c(0,Negloglikelihd) #neg_loglikelihd = (G(0):=0,G(T1),...,G(Tn))
return(Negloglikelihd)
}
# psi^* for the Cauchy density:
t0 <- newton(function(t) t * sin(t) + cos(t) - 1, 2)$root
x0 <- cot(t0 / 2)
psi_cauchy <- function(x,x0){
if (length(x) > 1) return(sapply(x, psi_cauchy, x0=x0))
x <- max(min(x, x0), -x0)
-2*x / (1 + x^2)
}
#############PLOT############
thetapilot<-0 #oracle
Xsorted<-sort(abs(X-thetapilot))
deltaX<-diff(c(0,Xsorted))
tailgrid<-(1:(N/100))*mean(deltaX)
Xplot<-c(0,Xsorted,tailgrid+Xsorted[N])
############# g*: negative score function ############
C<-symmetric_neg_decr_score_est(X,lambda_0=lambda_0)
#library(RSpectra) #svds() used in gradient descent
library(ggplot2)
library(gridExtra)
library(pracma)
#library(gnorm) #to generate generalized Gaussian
#rm(list = ls())  # clear all variables in workspace
#graphics.off()  # clear all plots
##set the penalization coefficient
lambda0 <- 1e-4
##sample size
N<-500
noise<-"gaussian"
noise<-"laplace"
noise<-"cauchy"
##generate data
if (noise=="gaussian"){
X<-rnorm(N,0,1)
}else if (noise=="cauchy"){
X<-rcauchy(N)
}else if (noise=="laplace"){
X<-rexp(N)
X<-X*sign(runif(N,-1,1))
}
##return (g'(0),g'(T1),...,g'(Tn)), where g = -psi is increasing
symmetric_neg_decr_score_est <- function(X, thetapilot=0, lambda_0=1e-4){
N<-length(X)
lambda<-lambda0*2*N*sd(X)^3 #sd(X)^3: to make lambda scale invariant
Xsorted<-sort(abs(X-thetapilot))
deltaX<-diff(c(0,Xsorted))
##small scale projected Newton
u<-c(0,rep(1,N)) # linear part of the objective function
D1<-t(matrix(replicate(N,deltaX),ncol=N))
D1[upper.tri(D1)] <- 0
A<-diag(x=1, nrow = N, ncol = N+1)
diag(A[,-1])<-1
D2<-diag(1/deltaX*lambda) #lambda= lambda0*2*N*sd(X)^3
B<-diag(x=1, nrow = N, ncol = N+1)
diag(B[,-1])<--1
Hess<-0.25*crossprod(D1%*%A)+t(B)%*%D2%*%B
# Here, Hess=0.5*Hessian of the objective function, (Hess%*%C-u)=0.5*gradient
##initialization, C=(g'(0),g'(T1),...,g'(Tn))
# objective function: t(C)%*%Hess%*%C - 2*t(u)%*%C
# g = -psi is monotone increasing
C<-solve(Hess,u)
C[C<0]<-0 #projection
###projected Newton
M<-20
for (i in 1:M) {
cat("Newton loop loss",t(C)%*%Hess%*%C-2*t(u)%*%C,"\n")
alpha<-1 #reset step size
# Fixed<-(C==0)*(Hess%*%C-u>0)
# Free<-!Fixed
Free<-(C>0)|(Hess%*%C-u<=0)
###no backtracking for alpha
# C[Free]<-C[Free]-alpha*Scaling[Free,Free]%*%(Hess%*%C-u)[Free]
# C[Free][C[Free]<0]<-0#projection
###backtracking
Ctemp<-C
gradient<-(Hess%*%C-u)[Free]
Update<-solve(Hess[Free,Free],gradient)
Ctemp[Free]<-C[Free]-alpha*Update
Ctemp[Free][Ctemp[Free]<0]<-0 #projection
while (t(Ctemp)%*%Hess%*%Ctemp-2*t(u)%*%Ctemp > t(C)%*%Hess%*%C-2*t(u)%*%C+0.5*t((Ctemp-C)[Free])%*%(2*gradient)) {
alpha<-alpha*0.8
print("shrink step size")
Ctemp[Free]<-C[Free]-alpha*Update
Ctemp[Free][Ctemp[Free]<0]<-0 #projection
}
if(sum((Ctemp-C)^2)<1e-30){
cat("the last update has Euclidean norm",sum((Ctemp-C)^2))
cat("the last step size",alpha)
C<-Ctemp
break
}
C<-Ctemp
}
return(C)
}
# Obtain (g*(0),g*(T1),...,g*(Tn)) from C=(g'(0),g'(T1),...,g'(Tn))
neg_dec_score<-function(X, C, thetapilot=0){
N<-length(X)
Xsorted<-sort(abs(X-thetapilot))
deltaX<-diff(c(0,Xsorted))
gvalues<-C[-1]+C[-(N+1)]
gvalues<-0.5*gvalues*deltaX
for (j in 2:N) {
gvalues[j]<-gvalues[j]+gvalues[j-1]
}
gvalues<-c(0,gvalues) #gvalues = (g*(0),g*(T1),...,g*(Tn))
return(gvalues)
}
######## G' = g*, neg_loglikelihd = (G(0):=0,G(T1),...,G(Tn)), no normalization########
neg_loglikelihd<-function(X, C, gvalues, thetapilot=0){
N<-length(X)
Xsorted<-sort(abs(X-thetapilot))
deltaX<-diff(c(0,Xsorted))
Negloglikelihd<-gvalues[-(N+1)]*deltaX+(C[-(N+1)]/2+(C[-1]-C[-(N+1)])/6)*deltaX^2
for (j in 2:N) {
Negloglikelihd[j]<-Negloglikelihd[j]+Negloglikelihd[j-1]
}
Negloglikelihd<-c(0,Negloglikelihd) #neg_loglikelihd = (G(0):=0,G(T1),...,G(Tn))
return(Negloglikelihd)
}
# psi^* for the Cauchy density:
t0 <- newton(function(t) t * sin(t) + cos(t) - 1, 2)$root
x0 <- cot(t0 / 2)
psi_cauchy <- function(x,x0){
if (length(x) > 1) return(sapply(x, psi_cauchy, x0=x0))
x <- max(min(x, x0), -x0)
-2*x / (1 + x^2)
}
#############PLOT############
thetapilot<-0 #oracle
Xsorted<-sort(abs(X-thetapilot))
deltaX<-diff(c(0,Xsorted))
tailgrid<-(1:(N/100))*mean(deltaX)
Xplot<-c(0,Xsorted,tailgrid+Xsorted[N])
############# g*: negative score function ############
C<-symmetric_neg_decr_score_est(X,lambda_0=lambda_0)
gvalues<-neg_dec_score(X,C)
Negloglikelihd<-neg_loglikelihd(X, C, gvalues)
NStailY<-gvalues[N+1]+tailgrid*C[N+1]
NSYplot<-c(gvalues,NStailY)
############# negative log-likelihood ############
NLLtailY<-Negloglikelihd[N+1]+tailgrid*gvalues[N+1]+tailgrid^2/2*C[N+1]
NLLYplot<-c(Negloglikelihd,NLLtailY)
Xmin<-min(Xsorted)
Xmax<-max(Xsorted)
if (noise=="gaussian"){
NS0Yplot<-Xplot
NLL0Yplot<-Xplot^2/2
}else if (noise=="cauchy"){
NS0Yplot<-2*Xplot/(1+Xplot^2)
NLL0Yplot<-log(1+Xplot^2) #we offset Negloglikelihd by log(pi) so that Negloglikelihd(0)=0
}else if (noise=="laplace"){
NS0Yplot<-sign(Xplot)
NLL0Yplot<-abs(Xplot) #we offset Negloglikelihd by log(2) so that Negloglikelihd(0)=0
}
mydf = data.frame(X = Xplot,NScore = NSYplot,NLL = NLLYplot,NScore0 = NS0Yplot,NLL0 = NLL0Yplot)
plotNS.obj <- ggplot(data=mydf)+geom_line(aes(x=X, y=NScore, color="NShat"))+geom_line(aes(x=X, y=NScore0, color="NS0"))+
scale_color_manual(name=NULL, breaks = c("NShat", "NS0"), values = c("NShat" = "darkblue", "NS0" = "red"),labels = c(expression(-hat(psi)),expression(-psi[0])))+
ylab("negative score function")+xlab(NULL)+
geom_vline(xintercept = Xmin,linetype="dotted")+ geom_vline(xintercept = Xmax,linetype="dotted")+
geom_point(data=data.frame(X = Xsorted), aes(x=X, y=0), color="green", shape=4, size=0.5)+
theme_minimal()+theme(legend.position=c(0.13,0.92))
plotNLL.obj <- ggplot(data=mydf)+geom_line(aes(x=X, y=NLL, color="NLLhat"))+geom_line(aes(x=X, y=NLL0, color="NLL0"))+
scale_color_manual(name=NULL, breaks = c("NLLhat", "NLL0"), values = c("NLLhat" = "darkblue","NLL0" = "red"),labels = c(expression(-hat(phi)),expression(-phi[0])))+
ylab("negative log-likelihood")+xlab(NULL)+
geom_vline(xintercept = Xmin,linetype="dotted")+ geom_vline(xintercept = Xmax,linetype="dotted")+
geom_point(data=data.frame(X = Xsorted), aes(x=X, y=0), color="green", shape=4, size=0.5)+
theme_minimal()+theme(legend.position=c(0.13,0.92))
grid.arrange(plotNS.obj, plotNLL.obj, ncol=2)
####################################
######gvalues = (g(0),g(T1),...,g(Tn))))#######
######C = (g'(0),g'(T1),...,g'(Tn))#######
cuts<-c(0,Xsorted)
gtheta<-function(theta,X1){
absdelta<-abs(X1-theta)
index<-findInterval(absdelta, cuts)
Values<-gvalues[index] #g(left end point)
distoleft<-absdelta-cuts[index]
Values<-Values+distoleft*C[index] #linear part
quadpts<-index!=N+1
quadindex<-index[quadpts]
Values[quadpts]<-Values[quadpts]+0.5*(C[quadindex+1]-C[quadindex])*distoleft[quadpts]^2/deltaX[quadindex]
Values<-Values*sign(X1-theta)
return(sum(Values))
}
###gprimetheta is d/dx g=-d/dtheta g
gprimetheta<-function(theta,X1){
absdelta<-abs(X1-theta)
index<-findInterval(absdelta, cuts)
Values<-C[index] #g(left end point)
quadpts<-index!=N+1
quadindex<-index[quadpts]
distoleft<-absdelta-cuts[index]
Values[quadpts]<-Values[quadpts]+(C[quadindex+1]-C[quadindex])*distoleft[quadpts]/deltaX[quadindex]
return(sum(Values))
}
# #######compare with the sample mean
# Thetahats<-NULL
# Thetatildes<-NULL
# for (j in 1:1000) {
#   #X1<-runif(N,-1,1)
#   X1<-rnorm(N)
#   #X1<-rgnorm(N, mu = 0, alpha = 1, beta = 4)
#   thetatilde<-mean(X1)
#   thetahat<-thetatilde #initialization
#
#   while (abs(gtheta(thetahat,X1))>1e-13*N) {
#     ###backtracking
#     # alpha<-1
#     # Update<-gtheta(thetahat,X1)/gprimetheta(thetahat,X1)
#     # if(abs(Update)<1e-12){break}
#     # thetatemp<-thetahat+alpha*Update
#     # while (abs(gtheta(thetatemp,X1))>abs(gtheta(thetahat,X1))) {
#     #   alpha<-0.8*alpha
#     #   thetatemp<-thetahat+alpha*Update
#     # }
#     # #print(alpha)
#     # #print(abs(gtheta(thetatemp,X1))-abs(gtheta(thetahat,X1)))
#     # thetahat<-thetatemp
#     ###no backtracking
#     Update<-gtheta(thetahat,X1)/gprimetheta(thetahat,X1)
#     thetahat<-thetahat+Update
#     if(abs(Update)<1e-12){break}
#   }
#   #print(abs(gtheta(thetahat,X1)))
#   Thetahats<-c(Thetahats,abs(thetahat))
#   Thetatildes<-c(Thetatildes,abs(thetatilde)/sqrt(2))
#   #divide the |mean-theta0| by sqrt(2) to balance the extra 1000 samples used for score matching
# }
# mean(Thetahats)
# mean(Thetatildes)
N=3
A <- diag(x = 1, nrow = N, ncol = N+1)
A
A %*% t(A)
N <- 7 # sample size of each fold
d <- 2 # dimension (p) of the design matrix X
beta_0 <- 3 * runif(d) + 1 # regression coefficients
mu <- 2 # intercept (population mean of Y)
lambda_0 <- 0.0001 # penalization coefficient
### Generate data
## Design matrix:
X <- matrix(rnorm(N * d, 0, 1), nrow = N)
# X <- array(X, c(N, d))
## normalized penalization coefficient
lambda <- lambda_0 * 2 * N * sd(X)^3 # sd(X)^3: to make lambda scale invariant
## Additive noise:
# Noise <- rcauchy(N)
# Noise <- runif(N, -1, 1)
Noise <- rnorm(N, 0, 1)
## log-concave, mean = median = 0, asymmetric
# Noise <- rnorm(N, 0, 1)
# negNoise <- (Noise < 0)
# Noise <- runif(N, - 2 * sqrt(2/pi), 0) * negNoise + Noise * (1-negNoise)
Y <- X %*% beta_0 + mu + Noise
### Step 1: Pilot estimation using OLS
Xtemp <- cbind(rep(1, N), X)
beta_pilot <- solve(t(Xtemp) %*% Xtemp, t(Xtemp) %*% Y) #beta_pilot[1] is the intercept
Residual_sorted <- sort(Y - Xtemp %*% beta_pilot)
delta_Residual <- diff(Residual_sorted)
### Step 2: Now use the residuals from Step 1 to estimate the score function
############ Shape-constrained splines
## Initialization
u <- c(0, rep(1, N))
D1 <- t(matrix(replicate(N, c(2, delta_Residual)), ncol = N))
D1[upper.tri(D1)] <- 0
A <- diag(x = 1, nrow = N, ncol = N+1)
diag(A[-1, 3:(N + 1)]) <- 1
A[1, 1] <- -1
D2 <- diag(1 / delta_Residual * lambda) #lambda =  lambda_0 * 2 * N * sd(X)^3
B <- diag(x = 1, nrow = N-1, ncol = N)
diag(B[, -1]) <- -1
Hess <- t(B) %*% D2 %*% B
Hess <- cbind(rep(0, N),Hess)
Hess <- rbind(rep(0, N + 1),Hess)
Hess <- 0.25 * crossprod(D1 %*% A) + Hess
d1
D1
delta_Residual
Hess <- t(B) %*% D2 %*% B
Hess <- cbind(rep(0, N),Hess)
Hess <- rbind(rep(0, N + 1),Hess)
Hess
Hess <- 0.25 * crossprod(D1 %*% A) + Hess
Hess
lambda0 <-0.0001
##sample size
N <- 5
##generate data
# X<-rexp(N)
# X<-X*sign(runif(N,-1,1))
# X<-runif(N,-1,1)
X<-rnorm(N, 0, 1)
# X<-rgnorm(N, mu = 0, alpha = 1, beta = 9) #generalized Gaussian
# X<-runif(N/2,-5,-3)
# X<-c(X,runif(N/2,2.5,5.5))
#log-concave, mean=median=0, asymmetric
# X<-rnorm(N, 0, 1)
# negX<-X<0
# X<-runif(N, -2 * sqrt(2/pi), 0) * negX +  X * (1 - negX)
lambda<-lambda0 * 2 * N * sd(X)^3 #sd(X)^3: to make lambda scale invariant
##setting theta_pilot
theta_pilot<-mean(X)
#theta_pilot<-0 #oracle if the noise is symmetric
X_sorted<-sort(X - theta_pilot)#T_1,T_2,...,T_N
deltaX<-diff(X_sorted)#deltaX[i]=T_{i+1}-T_i
# C=(-g(T_1),g'(T_1),g'(T_2),...,g'(T_N))
# g is -psi, monotone increasing
##small scale projected Newton
u<-c(0,rep(1,N))
D1<-t(matrix(replicate(N,c(2,deltaX)),ncol=N))
D1[upper.tri(D1)] <- 0
A<-diag(x=1, nrow = N, ncol = N+1)
diag(A[-1,3:(N+1)])<-1
A[1,1]<--1 #reparametrization, C[1]=-g(T_1)>0
####test if the matrix expression is correct####
# C<-runif(N+1, min=-0.3, max=0.2)
# CC<-C[-1]
# CC<-CC[-1]+CC[-N]
# CC<-0.5*CC*deltaX
# for (j in 2:(N-1)) {
#   CC[j]<-CC[j]+CC[j-1]
# }
# CC<-c(-C[1],CC-C[1])
# sum(CC^2)-t(C)%*%crossprod(D1%*%A)%*%C*0.25
################################################
D2<-diag(1/deltaX*lambda) #lambda=lambda0*2*N*sd(X)^3
B<-diag(x=1, nrow = N-1, ncol = N)
diag(B[,-1])<--1
####test if the matrix expression is correct####
# C<-runif(N+1, min=-0.3, max=0.2)
# CC<-C[-1]
# CC<-CC[-1]-CC[-N]
# CC<-CC^2/deltaX
# Hess<-t(B)%*%D2%*%B #Hess=0.5Hessian, (Hess%*%C-u)=0.5gradient
# Hess<-cbind(rep(0,N),Hess)
# Hess<-rbind(rep(0,N+1),Hess)
# lambda*sum(CC)-t(C)%*%Hess%*%C
################################################
Hess<-t(B)%*%D2%*%B
Hess<-cbind(rep(0,N),Hess)
Hess<-rbind(rep(0,N+1),Hess)
Hess<-0.25*crossprod(D1%*%A)+Hess
D1
diag(N)
N:1
D1[-1,-1]
D1
D1[-1,1]
matrix(D1[-1,1])
D1[1,-1]
t(matrix(replicate(N,deltaX),ncol=N))
